# BaJie-Chat

### é¡¹ç›®ç®€ä»‹

å…«æˆ’-Chatæ˜¯ä¸€ä¸ªåŸºäºã€Šè¥¿æ¸¸è®°ã€‹å‰§æœ¬ä¸­çŒªå…«æˆ’çš„å°è¯å’Œè¯­å¥ï¼Œä»¥åŠä½¿ç”¨InternLMè¿›è¡ŒQLoRAå¾®è°ƒå¾—åˆ°çš„æ¨¡ä»¿çŒªå…«æˆ’è¯­æ°”çš„èŠå¤©è¯­è¨€æ¨¡å‹ã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡æ¨¡å‹ä¸å…«æˆ’-Chatè¿›è¡Œå¯¹è¯ã€‚

### è®¾å¤‡è¦æ±‚

- CPUï¼šIntel Core i5 æˆ–ä»¥ä¸Š
- GPUï¼š(1/4) NVIDIA A100 æˆ–ä»¥ä¸Š
- å†…å­˜ï¼š32GB æˆ–ä»¥ä¸Š
- å­˜å‚¨ï¼šè‡³å°‘20GBå¯ç”¨ç©ºé—´

### æœ€ä½³å®è·µ

<details>
  <summary style="font-weight: bold; font-size: larger;">âš™ï¸éƒ¨ç½²BaJie-Chatåˆ°Linuxç¯å¢ƒä¸­</summary>

```bash
# git clone æœ¬ repo ä»¥åŠå…¶submodules
git clone --recurse-submodules https://github.com/JimmyMa99/BaJie-Chat.git

# è¿›å…¥æºç ç›®å½•
cd xtuner

# ä»æºç å®‰è£… XTuner
pip install -e '.[all]'
```

```bash
apt install git git-lfs -y
git lfs install
git clone https://www.modelscope.cn/Shanghai_AI_Laboratory/internlm2-7b.git
```

```bash
xtuner train my_config/zbj_internlm2_chat_7b_qlora_oasst1_e4.py --deepspeed deepspeed_zero2
```

```bash
xtuner convert pth_to_hf my_config/zbj_internlm2_chat_7b_qlora_oasst1_e4.py work_dirs/zbj_internlm2_chat_7b_qlora_oasst1_e4/{your checkpoint} process_data/hf_models/zbj
xtuner convert merge {your model path} process_data/hf_models/zbj process_data/merged_models/zbj
```

- ä½¿ç”¨ streamlit è¿›è¡Œå¯¹è¯ï¼šä¿®æ”¹ `web_demo.py` ä¸­çš„æ¨¡å‹è·¯å¾„
```diff
-     model = (AutoModelForCausalLM.from_pretrained('path/to/your/model',
-                                                 trust_remote_code=True).to(
-                                                     torch.bfloat16).cuda())
-     tokenizer = AutoTokenizer.from_pretrained('path/to/your/tokenizer',
-                                              trust_remote_code=True)
+     model = (AutoModelForCausalLM.from_pretrained('process_data/merged_models/zbj',
+                                                 trust_remote_code=True).to(
+                                                     torch.bfloat16).cuda())
+     tokenizer = AutoTokenizer.from_pretrained('process_data/merged_models/zbj',
+                                              trust_remote_code=True)
```

```bash
pip install streamlit
pip install transformers>=4.34
streamlit run ./web_demo.py
```
</details>

### æ•ˆæœå±•ç¤º

#### é¢„è§ˆ

![å…«æˆ’-Chat æˆªå›¾](./asserts/chat-demo.png)

#### OpenXLab é“¾æ¥

ğŸ²[åœ¨ OpenXLab ä¸Šå°è¯•](https://openxlab.org.cn/apps/detail/JimmyMa99/BaJie-Chat)

### æ•°æ®å¤„ç†

æœ¬é¡¹ç›®é‡‡ç”¨ã€Šè¥¿æ¸¸è®°ã€‹å‰§æœ¬ä¸­å…³äºçŒªå…«æˆ’çš„å°è¯å’Œè¯­å¥ä½œä¸ºè®­ç»ƒæ•°æ®ï¼ŒåŒæ—¶ä½¿ç”¨äº†InternLMè¿›è¡ŒQLoRAå¾®è°ƒä»¥ç”Ÿæˆæ›´åŠ è´´åˆçŒªå…«æˆ’é£æ ¼çš„è¯­è¨€ã€‚

è¯¦ç»†æ•°æ®å¤„ç†æµç¨‹è¯·å‚è€ƒä»¥ä¸‹é“¾æ¥ï¼š

- [æ•°æ®å¤„ç†æµç¨‹æ–‡æ¡£](https://github.com/JimmyMa99/BaJie-Chat/blob/main/tools/README.md)

### ç›¸å…³æ‹“å±•

- [XTuner GitHub é“¾æ¥](https://github.com/InternLM/xtuner)
- [InternLM GitHub é“¾æ¥](https://github.com/InternLM/InternLM/tree/main)
- [SanZang-Chat GitHub é“¾æ¥](https://github.com/JimmyMa99/SanZang-Chat)

### News

[2024.2.14]ï¼šå…«æˆ’-Chat æƒé‡å…¬å¼€è‡³[ModelScope](https://www.modelscope.cn/models/JimmyMa99/BaJie-Chat/summary) éƒ¨ç½²è‡³ [OpenXLab](https://openxlab.org.cn/apps/detail/JimmyMa99/BaJie-Chat)

[2024.2.16]ï¼šå…«æˆ’-Chat æ·»åŠ æ–‡è¨€æ–‡å’Œç™½è¯æ–‡æ•°æ®ï¼Œé‡æ–°è®­ç»ƒå¹¶éƒ¨ç½²

### Todo

- [x] qloraå¾®è°ƒçŒªå…«æˆ’
- [x] å¢æ·»æ–‡è¨€æ–‡å’Œç™½è¯æ–‡æ•°æ®ï¼Œä¼˜åŒ–åŸè‘—å¯¹è¯æ•°æ®
- [ ] å…¨é‡å¾®è°ƒçŒªå…«æˆ’
- [ ] æ¥å…¥lmdeployå®ç°openai api

### ç‰¹åˆ«é¸£è°¢

ç‰¹åˆ«æ„Ÿè°¢ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤çš„æ”¯æŒï¼

<hr>

ğŸ” æ¢ç´¢å…«æˆ’-Chat(Internlm-chat-7b)

[![Static Badge](https://img.shields.io/badge/-gery?style=social&label=ğŸ¤–%20ModelScope)](https://www.modelscope.cn/models/JimmyMa99/BaJie-Chat/summary)

<hr>

æ›´å¤šæ‹“å±•

[SanZang-Chat](https://github.com/JimmyMa99/SanZang-Chat)

[XTuner](https://github.com/InternLM/xtuner)

[InternLM](https://github.com/InternLM/InternLM/tree/main)
